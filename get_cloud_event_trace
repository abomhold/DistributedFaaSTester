#!/usr/bin/env bash

# Retrieves all log stream names for a given log group.
function get_log_streams() {
  aws logs describe-log-streams \
    --log-group-name "/trace" \
    | jq -r '.logStreams[].logStreamName'
}


# Iterates through the passed-in log streams and prints matching log events.
function log_event_loop() {
  for log_stream in "$@"; do
    aws logs get-log-events \
      --log-group-name "/trace" \
      --log-stream-name "$log_stream" \
      | jq -r '.events[].message' &
  done
}


function main() {
  # Set log_group from first argument or default to "/trace".
  local log_group="${1-/trace}"

  # Use mapfile to store the log stream list into an array.
  mapfile -t log_streams < <(get_log_streams)
  # Capture all matching events into an array.
  # Pass log_group first, followed by the list of log_streams.
  mapfile -t all_events < <(log_event_loop "${log_streams[@]}" | jq -s)

  # Print all events.
  for event in "${all_events[@]}"; do
    echo "$event"
  done
}

main "$@"

# Example JSON generator function (not currently used in the main flow).
# Execute main with all script arguments.
#function generate_event_json_object() {
#  local event_id="$1"
#  local time_from_start="$2"
#  local node_id="$3"
#  local payload="$4"
#  local endpoint="$5"
#
#  # We use `--argjson` when passing a JSON literal. For strings, we use `--arg`.
#  # Here, we interpret `event_id` as a JSON numeric type; adjust if needed.
#  jq -n \
#    --argjson eventID "$event_id" \
#    --arg timeFromStart "$time_from_start" \
#    --arg nodeID "$node_id" \
#    --argjson payload "$(echo "$payload" | jq -R '{"name": .}')" \
#    --arg endpoint "$endpoint" \
#    '$ARGS.named'
#}
